{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from PIL import ImageFilter, Image\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "#import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import init\n",
    "\n",
    "from pipeline.metrics import accuracy_sigmoid, accuracy_sigmoid_mean, log_loss_sigmoid\n",
    "from pipeline.model_methods import validate_vid_bf, train_vid_bf\n",
    "from pipeline.image_extracting import extract_faces, FastMTCNN, InceptionResnetV1, extract_faces_dlib, MTCNN\n",
    "from pipeline.blazeface import BlazeFace\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "PATH = \"model.h5\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "facedet = BlazeFace().to(device)\n",
    "facedet.load_weights(\"pipeline/blazeface.pth\")\n",
    "facedet.load_anchors(\"pipeline/anchors.npy\")\n",
    "_ = facedet.train(False)\n",
    "\n",
    "from pipeline.helpers.read_video_1 import VideoReader\n",
    "from pipeline.helpers.face_extract_1 import FaceExtractor\n",
    "\n",
    "frames_per_video = 17\n",
    "\n",
    "video_reader = VideoReader()\n",
    "video_read_fn = lambda x: video_reader.read_frames(x, num_frames=frames_per_video)\n",
    "face_extractor = FaceExtractor(video_read_fn, facedet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71210, 13129)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv('data\\\\metadata.csv')\n",
    "len(y_train[y_train.label == 1]), len(y_train[y_train.label == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.CenterCrop((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = r'D:\\Machine Learning\\deepfake-detection\\data\\train_set'\n",
    "x_val = r'D:\\Machine Learning\\deepfake-detection\\data\\validation_set'\n",
    "x_test = r'D:\\Machine Learning\\deepfake-detection\\data\\cross_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "class MyResNeXt(models.resnet.ResNet):\n",
    "    def __init__(self, training=True):\n",
    "        super(MyResNeXt, self).__init__(block=models.resnet.Bottleneck,\n",
    "                                        layers=[3, 4, 6, 3], \n",
    "                                        groups=32, \n",
    "                                        width_per_group=4)\n",
    "        self.fc = nn.Linear(2048, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyResNeXt()\n",
    "loss =  torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "#optimizer = torch.optim.Adam(model.fc.parameters(), lr=1e-3) \n",
    "#optimizer = torch.optim.SGD(model.model.last_linear.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "\n",
    "model.load_state_dict(torch.load(\"pretrained/resnext.pth\", map_location=device))\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "\n",
    "exceptions = ['last_linear']\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    for e in exceptions:\n",
    "        if e in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "\n",
    "'''\n",
    "ResNext50 - 0.8975 mean\n",
    "'''\n",
    "\n",
    "validate_vid_bf(model, x_test, y_train, loss, accuracy_sigmoid_mean, device, frames_per_video, face_extractor, print_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f687fc02bf247e2af3b467d630f6425",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032ca3261e334551bd673f0333b581ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metric, lost = train_vid_bf(model, loss, optimizer, scheduler, x_train, x_test, y_train, accuracy_sigmoid_mean, device, \n",
    "                            face_extractor, \n",
    "                            frames=10,\n",
    "                            epochs=10, \n",
    "                            batch_size=5, \n",
    "                            del_net=False, \n",
    "                            useScheduler=True,\n",
    "                            checkpoint=0.6,\n",
    "                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "min_lost = min(enumerate(lost), key=itemgetter(1))[0] \n",
    "min_metrics = max(enumerate(metric), key=itemgetter(1))[0] \n",
    "print(\"Loss optim:\", lost[min_lost], min_lost + 1)\n",
    "print(\"Metrics optim:\", metric[min_metrics], min_metrics + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(metric, label='model')\n",
    "plt.legend()\n",
    "plt.title('Validation metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lost, label='model')\n",
    "plt.legend()\n",
    "plt.title('Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_vi1d(model, x_val, y_train, loss, accuracy_b, device, 30, fast_mtcnn, transforms, \n",
    "             show_results=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_vid(model, x_val, y_train, loss, log_loss, device, 30, fast_mtcnn, transforms, print_results=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_vid(model, x_val, y_train, loss, log_loss, device, 30, fast_mtcnn, transforms, show_results=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_vid(model, x_val, y_train, loss, log_loss, device, 30, fast_mtcnn, transforms, show_graphic=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '0.657.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
