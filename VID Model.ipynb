{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "d:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\.libs\\libopenblas.IPBC74C7KURV7CB2PKT5Z5FNR3SIBV4J.gfortran-win_amd64.dll\n",
      "d:\\users\\user\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import cv2\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from functools import partial\n",
    "from dataclasses import dataclass\n",
    "from collections import OrderedDict\n",
    "import torchvision\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "from PIL import ImageFilter, Image\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "#import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import init\n",
    "\n",
    "from network.meso import Meso4, MesoInception4\n",
    "from network.models import model_selection, return_pytorch04_xception\n",
    "from network.lstm_deepfake import LSTMDF\n",
    " \n",
    "from pipeline.metrics import accuracy, log_loss, accuracy_b, log_loss_b, accuracy_b_mean\n",
    "from pipeline.model_methods import validate_img, train_img, validate_vid, train_vid\n",
    "from pipeline.data_loaders import load_img_dataset\n",
    "from pipeline.image_extracting import extract_faces, FastMTCNN, InceptionResnetV1, extract_faces_dlib, MTCNN\n",
    "\n",
    "from pipeline.blazeface import BlazeFace\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "PATH = \"model.h5\"\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71210, 13129)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.read_csv('data\\\\metadata.csv')\n",
    "len(y_train[y_train.label == 1]), len(y_train[y_train.label == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train = r'D:\\Machine Learning\\deepfake-detection\\data\\train_set'\n",
    "x_val = r'D:\\Machine Learning\\deepfake-detection\\data\\validation_set'\n",
    "x_test = r'D:\\Machine Learning\\deepfake-detection\\data\\cross_val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model, *_ = model_selection(modelname='xception', num_out_classes=2, dropout=None)\n",
    "#model = LSTMDF(dropout=0.5)\n",
    "model = models.resnext50_32x4d(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%script false\n",
    "\n",
    "#for param in model.parameters():\n",
    "#    param.requires_grad = False\n",
    "    \n",
    "model.fc = nn.Linear(2048, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "model.load_state_dict(torch.load('pretrained/best.pkl'))\n",
    "\n",
    "if isinstance(model, torch.nn.DataParallel):\n",
    "    model = model.module\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "\n",
    "model.load_state_dict(torch.load(\"pretrained/xception/full_raw.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "\n",
    "exceptions = ['last_linear']\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    for e in exceptions:\n",
    "        if e in name:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss =  torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3) \n",
    "#optimizer = torch.optim.Adam(model.model.last_linear.parameters(), lr=1e-3) \n",
    "#optimizer = torch.optim.SGD(model.model.last_linear.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_mtcnn = FastMTCNN(\n",
    "    stride=4,\n",
    "    resize=1,\n",
    "    margin=14,\n",
    "    factor=0.9,\n",
    "    #min_face_size=60,\n",
    "    #keep_all=True,\n",
    "    select_largest=True,\n",
    "    device=device\n",
    ")\n",
    "transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((299, 299)),\n",
    "    torchvision.transforms.CenterCrop((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    #torchvision.transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))\n",
    "    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "#resnet = InceptionResnetV1(pretrained='vggface2', device=device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "\n",
    "'''\n",
    "all_c40\n",
    "\n",
    "noisy 224 4 1 14 0.6 false false 10 20 0.99      | Validation: metrics  0.61 loss  1.5346809851754295\n",
    "noisy 244 4 1 14 0.6 false false 10 20 0.99      | Validation: metrics  0.55 loss  1.805389928239515\n",
    "noisy 256 4 1 14 0.6 false false 10 20 0.99      | Validation: metrics  0.625 loss  1.6223815120170137 | Test: 0.68081 LL 0.5812 ACC\n",
    "noisy 299 4 1 14 0.6 false false 10 20 0.99      | Validation: metrics  0.59 loss  1.5987016558059581\n",
    "'''\n",
    "\n",
    "'''\n",
    "full_raw dlib mean\n",
    "\n",
    "noisy 224 4 1 14 0.6 false false 10 20 0.99      | \n",
    "noisy 244 4 1 14 0.6 false false 10 20 0.99      | \n",
    "noisy 256 4 1 14 0.6 false false 10 20 0.99      | \n",
    "noisy 299 4 1 14 0.6 false false 10 20 0.99      | \n",
    "noisy 333 4 1 14 0.9 false false 10 20 0.99      | Validation: metrics  0.635 loss  0.6700506503431825\n",
    "'''\n",
    "\n",
    "validate_vid(model, x_test, y_train, loss, accuracy_b_mean, device, 10, fast_mtcnn, transforms,\n",
    "             print_results=True, \n",
    "             inference=nn.Softmax(dim=1), delimeter=20, remove_noise=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#faces = torch.FloatTensor(extract_faces(r'D:\\Machine Learning\\deepfake-detection\\data\\train_set\\aabqyygbaa.mp4', fast_mtcnn, transforms, limit=1, delimeter=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(faces[0].permute(1,2,0))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8e5ef60b654cf0b89294004ca3d4c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a234f69c32947608b4f5037d2968cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1250.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-ce3e47216504>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m                          \u001b[0mlimit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                          \u001b[0mdelimeter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                          \u001b[0mremove_noise\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                       )\n",
      "\u001b[1;32m~\\Desktop\\Projects\\dfdc-kaggle-solution\\pipeline\\model_methods.py\u001b[0m in \u001b[0;36mtrain_vid\u001b[1;34m(net, loss, optimizer, scheduler, X_train, X_test, y_train, metric, device, fast_mtcnn, transforms, epochs, batch_size, del_net, useInference, inference, useScheduler, checkpoint, limit, delimeter, remove_noise)\u001b[0m\n\u001b[0;32m    322\u001b[0m                     \u001b[0my_batch\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfaces\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 \u001b[0mX_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m                 \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "metric, lost = train_vid(model, loss, optimizer, scheduler, x_train, x_test, y_train, accuracy_b, device, fast_mtcnn, \n",
    "                         transforms, \n",
    "                         epochs=3, \n",
    "                         batch_size=4, \n",
    "                         del_net=False, \n",
    "                         useInference=False,\n",
    "                         inference=nn.Softmax(dim=1), \n",
    "                         useScheduler=True,\n",
    "                         checkpoint=0.7,\n",
    "                         limit=1,\n",
    "                         delimeter=25,\n",
    "                         remove_noise=False\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "min_lost = min(enumerate(lost), key=itemgetter(1))[0] \n",
    "min_metrics = max(enumerate(metric), key=itemgetter(1))[0] \n",
    "print(\"Loss optim:\", lost[min_lost], min_lost + 1)\n",
    "print(\"Metrics optim:\", metric[min_metrics], min_metrics + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(metric, label='model')\n",
    "plt.legend()\n",
    "plt.title('Validation metrics')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lost, label='model')\n",
    "plt.legend()\n",
    "plt.title('Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_vi1d(model, x_val, y_train, loss, accuracy_b, device, 30, fast_mtcnn, transforms, \n",
    "             show_results=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_vid(model, x_val, y_train, loss, log_loss, device, 30, fast_mtcnn, transforms, print_results=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_vid(model, x_val, y_train, loss, log_loss, device, 30, fast_mtcnn, transforms, show_results=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_vid(model, x_val, y_train, loss, log_loss, device, 30, fast_mtcnn, transforms, show_graphic=True, inference=nn.Softmax(dim=1), delimeter=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), '0.657.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
